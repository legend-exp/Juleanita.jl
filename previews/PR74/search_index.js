var documenterSearchIndex = {"docs":
[{"location":"ML_QC/#Quality-Cuts-with-Machine-Learning:-AP-SVM","page":"ML Quality Cuts","title":"Quality Cuts with Machine Learning: AP-SVM","text":"","category":"section"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"This ML quality cut implementation is based on the strategy developed by Esteban Le√≥n: üêô AP-SVM-Data-Cleaning, üìñ Publication","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"In the first part, this documentgives an overview of the AP-SVM strategy. The the second part, the code workflow is explained. ","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"The ML-based quality cuts follow a two-step approach:","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"Affinity Propagation (AP) \nSupport Vector Machine (SVM)  ","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"‚ö†Ô∏è Note on Automation:    The machine learning-based quality cuts aren't fully automated. Unlike other processing steps (e.g. DSP, energy calibration), automation is not possible due to the requirement for manual relabeling of exemplars (see step 1.2 and 03_AP_relabel.jl).  Therefore, the ML quality cuts are provided as standalone scripts that must be manually adapted to suit your specific use case.","category":"page"},{"location":"ML_QC/#Strategy","page":"ML Quality Cuts","title":"Strategy","text":"","category":"section"},{"location":"ML_QC/#1.-Affinity-Propagation-(AP)","page":"ML Quality Cuts","title":"1. Affinity Propagation (AP)","text":"","category":"section"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"AP is an unsupervised clustering algorithm used to group similar waveforms.\nGoal: Cluster waveforms into groups based on waveform type.\nAP performs three key tasks:\nDetermines the number of clusters present in the data.\nIdentifies exemplars ‚Äî representative waveforms for each cluster.\nAssigns each waveform a label, referred to as the AP label (an integer between 1 and n_clusters).","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"Due to its high memory usage, AP is applied only to a subset of the data (typically ‚â§ 10,000 waveforms).","category":"page"},{"location":"ML_QC/#1.1-Hyperparameter-optmization","page":"ML Quality Cuts","title":"1.1 Hyperparameter optmization","text":"","category":"section"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"Affinity propagation has two hyperparameters: the preference and the damping. ","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"preference\nControls how likely a data point is to be chosen as a cluster center (exemplar).\nLower values (more negative) ‚Üí fewer clusters\nHigher values (less negative) ‚Üí more clusters\ndefault: median of similarity matrix\ndamping\nA factor used to control the update rate during the clustering process.\nHelps stabilize the iterative message-passing algorithm and avoid oscillations.\nMust be set between 0.5 and < 1.0.\nLower values (closer to 0.5) ‚Üí faster updates, but can lead to instability\nHigher values (closer to 1.0) ‚Üí more stable, but slower convergence","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"Our goal is to optimize the hyperparameters with respect to cluster size (and convergence). The want to have around 100 clusters, and the algorithm should of course converge within a reasonable time. Less clusters would not capture the diversity of waveforms and more clusters would be infeasible to relabel by hand (see next step).","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"This figure shows an example of AP hyperparameter optimization. In case the AP didn't converge for a (preference, damping)-configuration, the grid point is colored grey. ","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"(Image: AP hyperparameter optimization) Figure 1: AP-hyperparameter optimization","category":"page"},{"location":"ML_QC/#1.2-AP-apply-to-training-set-and-assign-qc-labels.","page":"ML Quality Cuts","title":"1.2 AP apply to training set and assign qc-labels.","text":"","category":"section"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"Now we run AP with the optimial (or guessed) hyperparameters. ","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"The resulting clusters are initially labeled with arbitrary numeric IDs (e.g., 1 to n_clusters), that we refer to as \"AP labels\". ","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"In a manual post-processing step, we map these numeric AP labels to meaningful quality control (QC) labels using a predefined legend.","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"QC Label Description\n0 normal\n1 neg. going\n2 up slope\n3 down slope\n4 spike\n5 x-talk\n6 slope rising\n7 early trigger\n8 late trigger\n9 saturated\n10 soft pileup\n11 hard pileup\n12 bump\n13 noise","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"(Image: Exemplars with AP-labels) Figure 2: Exemplars with AP-labels","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"(Image: Exemplars with QC-labels) Figure 3: Exemplars with QC-labels","category":"page"},{"location":"ML_QC/#2.-Support-Vector-Machine-(SVM)","page":"ML Quality Cuts","title":"2. Support Vector Machine (SVM)","text":"","category":"section"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"SVM is a supervised learning algorithm. We train the SVM on the same waveforms used for AP, using the QC labels assigned in the previous step.","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"Once trained, the SVM model can predict QC labels for new, unseen waveforms‚Äîeffectively scaling the AP-based classification to larger datasets.","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"(Image: Example of QC-labels obtained from AP-SVM model) Figure 4: Example of QC-labels obtained from AP-SVM model on training data set","category":"page"},{"location":"ML_QC/#AP-SVM-Workflow-Scripts","page":"ML Quality Cuts","title":"AP-SVM Workflow Scripts","text":"","category":"section"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"The following scripts implement the AP-SVM quality cut workflow:","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"01_AP_hyperpars_opt.jl  \nRuns the Affinity Propagation (AP) model over a grid of hyperparameter combinations to find best combination.  \nThis script will output a report, which summarizes the number of clusters for each grid point. \nFor the next step, select a (perference, damping)-combination that results in approximately 100 clusters.\nSince this step is the most computational expensive one, it should be run via a SLURM script on a computing cluster (bash script might need modifications for your cluster specs): \nsbatch run_AP_opt.sh \nFor first tests, you can also skip this step and just guess a hyperparameter combination. \n02_AP_train.jl  ","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"Runs the AP clustering algorithm and saves intermediate results, including:     - AP labels for each waveform     - Indices of cluster centers (waveforms)","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"In case you use many waveforms (> 1,000) for AP training, it might be handy run the script in batch mode:\n> `sbatch run_AP_train.sh`","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"03_AP_relabel.jl  \nPerforms manual relabeling of cluster centers, mapping AP labels to meaningful QC labels.  \nSaves the updated AP results.\n04_SVM.jl  \nTrains and evaluates the Support Vector Machine (SVM) model.  \nThe waveforms used in AP are split into training and test sets.  \nThe script validates the classification performance of the SVM. Save SVM results.\n05_Apply_AP-SVM.jl  \nApplies the trained AP-SVM model to unseen data, such as all waveforms from a full run.","category":"page"},{"location":"ML_QC/","page":"ML Quality Cuts","title":"ML Quality Cuts","text":"‚ö†Ô∏è Note: SVM hyperparameters are currently not optimized.   Future improvements should include hyperparameter tuning to enhance model performance.","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Modules","page":"API","title":"Modules","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Order = [:module]","category":"page"},{"location":"api/#Types-and-constants","page":"API","title":"Types and constants","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Order = [:type, :constant]","category":"page"},{"location":"api/#Functions-and-macros","page":"API","title":"Functions and macros","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Order = [:macro, :function]","category":"page"},{"location":"api/#Documentation","page":"API","title":"Documentation","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [Juleanita]\nOrder = [:module, :type, :constant, :macro, :function]","category":"page"},{"location":"api/#Juleanita.electron_charge","page":"API","title":"Juleanita.electron_charge","text":"electron_charge\n\ncharge of electron in Coulomb: e = 160217662 10^-19 C\n\n\n\n\n\n","category":"constant"},{"location":"api/#Juleanita.GeBandgap-Tuple{Real}","page":"API","title":"Juleanita.GeBandgap","text":"GeBandgap(T::Real)\n\nbandgap energy (eV) of germanium as a function of temperature (K)\n\nE_textrmgap(T) = 0744 - frac4774 cdot 10^-4 cdot T^2T + 235\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.Ge_Energy_per_eholePair-Tuple{Real}","page":"API","title":"Juleanita.Ge_Energy_per_eholePair","text":"Ge_Energy_per_eholePair(T::Real)\n\nenergy (eV) required to create an electron-hole pair in germanium as a function of temperature (K)\n\nE(T)  = 22 cdot E_textrmgap(T) + 199 cdot E_textrmgap(T)^32 cdot exp(475 cdot fracE_textrmgap(T)T)\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.Ge_NumberChargeCarrier-Tuple{Real, Real}","page":"API","title":"Juleanita.Ge_NumberChargeCarrier","text":"Ge_NumberChargeCarrier(E::Real, T::Real)\n\nnumber of charge carriers created by an energy E (eV) in germanium at temperature T (K)\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.V_to_electrons-Tuple{Real, Real}","page":"API","title":"Juleanita.V_to_electrons","text":"V_to_electrons(Voltage_V::Real, capacitance_F::Real; gain::Real = 1.0)\n\nConvert voltage into a charge in electrons based on the capacitance of the system (could be pulser, detector, or combination).\n\nQe^-  =  fracVtextrmgain cdot fracC_textrminje^-\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita._ADC_to_V-Tuple{Real, Real, Int64}","page":"API","title":"Juleanita._ADC_to_V","text":"_ADC_to_V(ADC::Real, dynamicrange_V::Real, bits::Int)\n\nConvert ADC-code from digitizer into voltage. The ADC-code is assumed to be in the range [0, 2^bits] corresponding to voltages within the dynamic range.\n\nV  = fracV_textrmdynamic range2^textrmbits cdot textrmADC\n\nInputs:\n\nADC: ADC-code from digitizer\ndynamicrange_V: dynamic range of the DAQ in Volts\nbits: number of bits of the ADC\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita._ADC_to_electrons-Tuple{Real, Real}","page":"API","title":"Juleanita._ADC_to_electrons","text":"_ADC_to_electrons(ADC::Real, capacitance_F::Real; bits::Int = 14, dynamicrange_V::Real = 2.0, gain::Real = 1.0)\n\nConvert ADC-code from pulser into injected charge in pulserADCto_electrons\n\nQe^-  = (fracV_textrmdynamic range2^textrmbits cdot textrmADC) cdot frac1textrmgain cdot fracC_textrminje^-\n\nInputs:\n\nADC: ADC-code from digitizer  \ncapacitance_F: capacitance of the system (could be pulser, detector, or combination) in Farad\nbits: number of bits of the ADC\ndynamicrange_V: dynamic range of the DAQ in Volts\ngain: gain of the system\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita._ADC_to_keV-Tuple{Real, Real}","page":"API","title":"Juleanita._ADC_to_keV","text":"pulser_ADC_to_keV(ADC::Real, capacitance_F::Real; bits::Int = 14, dynamicrange_V::Real = 2.0, gain::Real = 1.0)\n\nConvert ADC-code from pulser into injected energy in keV. Inputs: \n\nADC: ADC-code from digitizer\ncapacitance_F: capacitance of the system (could be pulser, detector, or combination) in Farad\nbits: number of bits of the DAQ\ndynamicrange_V: dynamic range of the ADC in Volts\ngain: gain of the system\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita._is_valid_datestr-Tuple{AbstractString}","page":"API","title":"Juleanita._is_valid_datestr","text":"_is_valid_datestr(timestr_file::String; timezone::String = \"PT\")\n\ncheck if the time string in the filename is a valid date string\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.apply_qc-Tuple{Union{PropDicts.PropDict, TypedTables.Table}, PropDicts.PropDict}","page":"API","title":"Juleanita.apply_qc","text":"quality cuts based on dsp parameters\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.csv_to_lh5-Tuple{LegendDataManagement.LegendData, LegendDataManagement.DataPeriod, LegendDataManagement.DataRun, Union{Symbol, LegendDataManagement.DataCategory}, LegendDataManagement.ChannelId, String}","page":"API","title":"Juleanita.csv_to_lh5","text":"csvtolh5(data::LegendData, period::DataPeriod, run::DataRun, category::DataCategoryLike, channel::ChannelId, csv_folder::String; heading::Int = 17, nwvfmax::Union{Int, Float64, Vector{Int64}} = NaN, nChannels::Int = 2,          ti::ClosedInterval{<:Quantity} = 0.0u\"¬µs\".. 550.0u\"¬µs\")\n\nconverts csv files from oscilloscope to lh5 files\nformat of csv file matches the one from an oscilloscope...might be different for other systems\nsaves the lh5 files in the raw tier defined in \"LEGENDDATACONFIG\"\n\nINPUTS:\n\ndata::LegendData LegendData object. You need \"LEGEND_DATA_CONFIG\" to construct this. this will define later where .lh5 files are saved\nperiod::DataPeriod data period that you want to assign your data to \nrun::DataRun data run that you want to assign your data to \ncategory::DataCategoryLike data category that you want to assign your data to\nchannel::ChannelId channel id that you want to assign your data to\ncsv_folder::String folder where the csv files are located\ncsv_heading::Int number of lines to skip in csv file\nnwvfmax::Union{Int, Float64, Vector{Int64}} number of waveforms to read OR vector of waveforms indices to read\nnChannels::Int number of channels in csv files to read (supports only 1 or 2)\nti::ClosedInterval{<:Quantity} time interval to truncate the waveforms to\nwpf::Int waveforms per files ‚Äì> number of waveforms to write per .lh5 file\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.fit_linearity-Union{Tuple{T}, Tuple{Int64, AbstractVector{<:Measurements.Measurement{<:T}}, AbstractVector{<:Measurements.Measurement{<:T}}}} where T<:Real","page":"API","title":"Juleanita.fit_linearity","text":"fit_linearity(pol_order::Int, ¬µ::AbstractVector{<:Union{Real,Measurement{<:Real}}}, peaks::AbstractVector{<:Union{Real,Measurement{<:Real}}}; pull_t::Vector{<:NamedTuple}=fill(NamedTuple(), pol_order+1), v_init::Vector = [], uncertainty::Bool=true )\n\nFit the calibration lines with polynomial function of polorder order     polorder == 1 -> linear function     pol_order == 2 -> quadratic function\n\nReturns\n\n* `result`: NamedTuple with the following fields\n    * `par`: best-fit parameters\n    * `gof`: godness of fit\n* `report`:\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.noise_sweep","page":"API","title":"Juleanita.noise_sweep","text":"noise_sweep(filter_type::Symbol, wvfs::ArrayOfRDWaveforms, dsp_config::DSPConfig, œÑ_pz::Quantity{T}; ft::Quantity{T}= 0.0u\"¬µs\", œÑ_cusp::Quantity{<:AbstractFloat} = 10000000.0u\"¬µs\", œÑ_zac::Quantity{<:AbstractFloat} = 10000000.0u\"¬µs\" ) where T<:Real\nnoise_sweep(filter_type::Symbol, wvfs::ArrayOfRDWaveforms, dsp_config::DSPConfig; kwargs... )\n\nNoise sweep function used in DSP filter optimizatio. The goal is to find the optimal rise-time (for a given flat-top time) which minimizes ENC noise. This is an alternative approach to dsp_trap_rt_optimization.\n\nStrategy:\n\nShift waveforms to have a common baseline, and deconvolute them with the pole-zero correction (in case œÑ_pz > 0.0u\"¬µs\" )\nFilter waveforms with given rise-time and flat-top time\nBuild histogram out of all samples in baseline from all waveforms. Remove bins at the beginning and end of the waveform to avoid edge effects.\nCalculate the RMS of the baseline noise ‚Äì> ENC noise\n\nInputs:\n\nfilter_type::Symbol: filter type (:trap or :cusp)\nwvfs::ArrayOfRDWaveforms: raw waveforms to be filtered\ndsp_config::DSPConfig: DSP configuration object containing relevant parameters: ft, grid_rt, bl_window, flt_length_cusp,  flt_length_zac\nœÑ_pz::Quantity{T}: pole-zero decay time. If œÑ_pz = 0.0u\"¬µs\" (or none given), no pole-zero correction is applied.\n\nkwargs:\n\nft::Quantity{T}: fixed flat-top time for optimization\nœÑ_cusp::Quantity{<:AbstractFloat}: cusp decay time; only relevant for cusp filter\nœÑ_zac::Quantity{<:AbstractFloat}: cusp decay time; only relevant for zac filter\n\n\n\n\n\n","category":"function"},{"location":"api/#Juleanita.process_ctc-Tuple{LegendDataManagement.LegendData, LegendDataManagement.DataPeriod, LegendDataManagement.DataRun, Union{Symbol, LegendDataManagement.DataCategory}, LegendDataManagement.ChannelId, PropDicts.PropDict, PropDicts.PropDict}","page":"API","title":"Juleanita.process_ctc","text":"process_ctc(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId, ecal_config::PropDict, ctc_config::PropDict;\n            energy_types::Vector{Symbol} = Symbol.(ctc_config.energy_types), reprocess::Bool = false)\nprocess_ctc(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId; kwargs...)\n\nCalculate charge-trapping correction: by looking at correlation between drift time and energy. Save correction function to rpars.  Inputs:\n\ndata::LegendData: LegendData object\nperiod::DataPeriod: data period\nrun::DataRun: data run\ncategory::Union{Symbol, DataCategory}: data category, e.g. :cal\nchannel::ChannelId: channel id\necal_config::PropDict: energy calibration configuration. If not specified use default from metadata\nctc_config::PropDict: charge-trapping correction configuration. If not specified use default from metadata\n\nOptional:\n\nenergy_types::Vector{Symbol}: energy types to process\nreprocess::Bool: reprocess the files or not\njuleana_logo::Bool: add juleana logo to plots\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.process_decaytime","page":"API","title":"Juleanita.process_decaytime","text":"process_decaytime(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId, min_œÑ::Quantity{T}, max_œÑ::Quantity{T}, nbins::Int, rel_cut_fit::Real, peak::Symbol, bl_window::ClosedInterval{<:Unitful.Time{<:T}}, tail_window::ClosedInterval{<:Unitful.Time{<:T}}; reprocess::Bool = false) where T <: Real\n\nprocess_decaytime(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId, pz_config::PropDict, bl_window::ClosedInterval{<:Unitful.Time{<:T}}, tail_window::ClosedInterval{<:Unitful.Time{<:T}}; kwargs...) where T <: Real\n\nprocess_decaytime(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId, pz_config::PropDict, dsp_config::DSPConfig; kwargs...)\n\nprocess_decaytime(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId; kwargs...)\n\nGoal: calculate decay time used for pole-zero correction Inputs:\n\ndata::LegendData: LegendData object\nperiod::DataPeriod: data period\nrun::DataRun: data run\ncategory::Union{Symbol, DataCategory}: data category, e.g. :cal\nchannel::ChannelId: channel id\nmin_œÑ::Quantity{T}: minimum decay time\nmax_œÑ::Quantity{T}: maximum decay time\nnbins::Int: number of bins for histogram\nrel_cut_fit::Real: relative cut for truncated gauss\npeak::Symbol: peak to use for decay time calculation. Can also be :all to use all :raw instead of :jlpeaks tier\nbl_window::ClosedInterval{<:Unitful.Time{<:T}}: baseline window\ntail_window::ClosedInterval{<:Unitful.Time{<:T}}: tail window\n\nOptional:\n\nreprocess::Bool: reprocess the files or not\njuleana_logo::Bool: add juleana logo to plots\n\n\n\n\n\n","category":"function"},{"location":"api/#Juleanita.process_dsp","page":"API","title":"Juleanita.process_dsp","text":"process_dsp(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId, dsp_config::DSPConfig, œÑ_pz::Quantity{<:Real}, pars_filter::PropDict; reprocess::Bool = false )  \nprocess_dsp(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId ; kwargs... )\n\nGoal: \n\nrun the DSP processing for all raw files in the given period, run, category and channel.\nbased on simple_dsp function\nsave the results in the jldsp tier\nif reprocess is false, it will skip the files that are already processed\n\nINPUTS:     - data::LegendData LegendData object. You need \"LEGEND_DATA_CONFIG\" to construct this, e.g. l200 = LegendData(:l200)     - period::DataPeriod data period, e.g. DataPeriod(1)     - run::DataRun data run, e.g. DataRun(1)     - category::Symbol data category, e.g. DataCategory(:cal)     - channel::ChannelId channel id, e.g. ChannelId(1) (depending on your data!)     - dsp_config::DSPConfig DSP configuration object. If not specified will take default from metadata     - œÑ_pz::Quantity{<:Real} decay time used for pole-zero correction. If not specified will take from rpars.pz     - pars_filter::PropDict optimized filter parameters used in DSP. If not specified will take from rpars.fltopt\n\nKWARGS:     - reprocess::Bool reprocess the files or not\n\nOUTPUTS:     - save the DSP results in the jldsp tier     - print the progress     - print the completion message\n\n\n\n\n\n","category":"function"},{"location":"api/#Juleanita.process_energy_calibration","page":"API","title":"Juleanita.process_energy_calibration","text":"process_energy_calibration(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId, source::Symbol; reprocess::Bool = true, ecal_config::PropDict = data.metadata.config.energy.energy_config.default, e_types::Vector{<:Symbol} = [:e_trap, :e_cusp, :e_zac])\n\nperform energy calibration: take uncalibration energy values from dsp files and calibrate them using calibration sources INPUTS:\n\ndata::LegendData: LegendData object\nperiod::DataPeriod: data period\nrun::DataRun: data run\ncategory::Union{Symbol, DataCategory}: data category, e.g. :cal\nchannel::ChannelId: channel id\nsource::Symbol: calibration source. :th228 or :co60 are supported at the moment\n\nOPTIONAL:\n\nreprocess::Bool: reprocess the files or not\necal_config::PropDict: energy calibration configuration. if not specified, it will take the default from metadata\netypes::Vector{<:Symbol}: energy types to calibrate. default is [:etrap, :ecusp, :ezac]\n\nOUTPUT:\n\nsave the calibration parameters as json files to disk (in generated/par/rpars/ecal/...) \nsave the calibration plots to disk (in generated/jlplt/rplt/...)\n\n\n\n\n\n","category":"function"},{"location":"api/#Juleanita.process_filteropt","page":"API","title":"Juleanita.process_filteropt","text":"process_filteropt(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId, dsp_config::DSPConfig, œÑ_pz::Quantity{T}, peak::Symbol; rt_opt_mode::Symbol = :blnoise, reprocess::Bool = false, filter_types::Vector{Symbol} = [:trap, cusp])\nprocess_filteropt(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId; kwargs...)\n\nFilter optimization for filter_types\n\nload waveforms from peakfile, shift baseline and pole-zero \noptimize rise-time for minimum baseline noise after filtering\noptimize flat-top time for FWHM of peak\nsave results to disk\nsanity plots for rise-time and flat-top time optimization\n\nInputs: \n\ndata::LegendData: LegendData object\nperiod::DataPeriod: data period\nrun::DataRun: data run\ncategory::Union{Symbol, DataCategory}: data category, e.g. :cal\nchannel::ChannelId: channel id\n\nOptional:\n\ndsp_config::DSPConfig: DSP configuration object. If not specified will take default from metadata\nœÑ_pz::Quantity{T}: pole-zero decay time.  If not specified will take default from metadata\npeak::Symbol: peak to optimize for (needs existing peakfile!). If not specified will take default from metadata\nrt_opt_mode::Symbol: mode for rise-time optimization (:blnoise or :pickoff) ‚Äì> two different strategies for optimization\nreprocess::Bool: reprocess the files or not\nfilter_types::Vector{Symbol}: filter types to optimize for\n\n\n\n\n\n","category":"function"},{"location":"api/#Juleanita.process_hit-Tuple{LegendDataManagement.LegendData, LegendDataManagement.DataPeriod, LegendDataManagement.DataRun, Union{Symbol, LegendDataManagement.DataCategory}, LegendDataManagement.ChannelId}","page":"API","title":"Juleanita.process_hit","text":"processing_hit(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId; reprocess::Bool = false, e_types::Vector{<:Symbol} = [:e_trap, :e_cusp, :e_zac])\n\nrun the hit processing for all dsp files in the given period, run, category and channel.\napply energy calibration to the dsp energy estimator and save the results in the jlhit tier \nno PSD at the moment, will be added in future \nif reprocess is false, it will skip the files that are already processed\n\nINPUTS:\n\ndata::LegendData LegendData object\nperiod::DataPeriod data period\nrun::DataRun data run\ncategory::Union{Symbol, DataCategory} data category, e.g. :cal\nchannel::ChannelId channel id\nreprocess::Bool reprocess the files or not\ne_types::Vector{<:Symbol} energy types to process. default is [:etrap, :ecusp, :e_zac]\n\nOUTPUTS:\n\nsave the hit results in the jlhit tier\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.process_peak_split","page":"API","title":"Juleanita.process_peak_split","text":"process_peak_split(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId, ecal_config::PropDict, dsp_config::DSPConfig, qc_config::PropDict; reprocess::Bool = false)\nprocess_peak_split(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId; kwargs...)\n\nCreate peak files containting only waveforms from peaks in the calibration spectrum.\n\nRead raw data\nFind peaks in the calibration spectrum using rough energy estimate data_fk.daqenergy\nDo simple DSP for peaks only \napply quality cuts based on simple DSP\nSave waveforms after QC to peak files\n\ninputs:\n\ndata: LegendData object\nperiod: DataPeriod object\nrun: DataRun object\ncategory: Symbol or DataCategory object, e.g. :cal for calibration \nchannel: ChannelId for germanium detector \necal_config: PropDict, energy calibration configuration\ndsp_config: DSPConfig, DSP configuration\nqc_config: PropDict, quality cut configuration\n\nkeyword arguments:\n\nreprocess: Bool, default is false\n\nOutput:\n\nh_uncals histograms of peaksearch\npeakpos \n\nAlso, peak files containting only waveforms from peaks in the calibration spectrum are saved to jlpeaks folder.\n\n\n\n\n\n","category":"function"},{"location":"api/#Juleanita.process_peakfits","page":"API","title":"Juleanita.process_peakfits","text":"progress_peakfits(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId; reprocess::Bool = true, e_types::Vector{<:Symbol} = [:e_trap, :e_cusp, :e_zac], juleana_logo::Bool = false)\nProcess the peak fits for the benchtest data.\n\n\n\n\n\n","category":"function"},{"location":"api/#Juleanita.process_pulser_linearity","page":"API","title":"Juleanita.process_pulser_linearity","text":"\n\n\n\n","category":"function"},{"location":"api/#Juleanita.process_qualitycuts","page":"API","title":"Juleanita.process_qualitycuts","text":"process_qualitycuts(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId; reprocess::Bool = false, qc_config::PropDict = data.metadata.config.qc.qc_config.default)\n\napply quality cuts based on dsp parameters  inputs:      data: LegendData object     period: DataPeriod object     run: DataRun object     category: Symbol or DataCategory object     channel: ChannelId object     reprocess: Bool, default false     qcconfig: PropDict, default data.metadata.config.qc.qcconfig.default\n\n\n\n\n\n","category":"function"},{"location":"api/#Juleanita.read_csv_metadata-Tuple{String}","page":"API","title":"Juleanita.read_csv_metadata","text":"read_csv_metadata(filepath::String; heading::Int = 17, nChannels::Int = 2, timezone = \"PT\")\n\nread metadata from a csv file (as taken from oscilloscope) input:\n\nfilepath::String: file name\nheading::Int: number of lines (beginning at top) in csv file contain metadata \nnChannels::Int: number of channels in csv file\ntimezone::String: timezone to which the timekey in filename refers (standard is PT = Pacific Time ‚Äì> Berkeley)\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.read_folder_csv_oscilloscope-Tuple{String}","page":"API","title":"Juleanita.read_folder_csv_oscilloscope","text":"read_folder_csv_oscilloscope(csv_folder::String; heading::Int = 17, nwvfmax::Union{Int, Float64, Vector{Int64}} = NaN, nChannels::Int = 2)\n\nread folder with csv files from oscilloscope input:\n\ncsv_folder::String: absolute csv folder path\nheading::Int: number of lines to skip\nnwvfmax::Union{Int, Float64, Vector{Int64}}: number of waveforms to read OR vector of waveforms indices to read\nnChannels::Int: number of channels in csv files to read (1 or 2)\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.rms-Union{Tuple{Vector{T}}, Tuple{T}} where T<:Real","page":"API","title":"Juleanita.rms","text":"rms(x::Vector{T}) where {T <: Real}\n\nCalculate the RMS of a vector of real numbers.\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.simple_dsp-Union{Tuple{T}, Tuple{Q}, Tuple{Q, LegendDSP.DSPConfig}} where {Q<:TypedTables.Table, T<:Real}","page":"API","title":"Juleanita.simple_dsp","text":"simple_dsp(data::Q, dsp_config::DSPConfig; œÑ_pz::Quantity{T} = 0.0u\"¬µs\", pars_filter::PropDict) where {Q <: Table, T<:Real}\n\ndsp routine which calculates all relevant parameters for the waveform analysis\n\ndata::Q: input data, e.g. raw file, peakfile \ndsp_config::DSPConfig: DSP configuration object\nœÑ_pz::Quantity{T}: pole-zero decay time. If œÑ_pz = 0.0u\"¬µs\" (or none given), no pole-zero correction is applied.\npars_filter::PropDict: filter parameters for the different filter types. Use PropDict() to get default values from config.\n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.simple_dsp_pulser-Union{Tuple{T}, Tuple{Q}, Tuple{Q, LegendDSP.DSPConfig}} where {Q<:TypedTables.Table, T<:Real}","page":"API","title":"Juleanita.simple_dsp_pulser","text":"simple_dsp_pulser(data::Q, dsp_config::DSPConfig; œÑ_pz::Quantity{T} = 0.0u\"¬µs\", pars_filter::PropDict) where {Q <: Table, T<:Real}\n\nminimal version of simple_dsp for pulser channel \n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.simple_dsp_qc-Union{Tuple{T}, Tuple{Q}, Tuple{Q, LegendDSP.DSPConfig}} where {Q<:TypedTables.Table, T<:Real}","page":"API","title":"Juleanita.simple_dsp_qc","text":"minimal version of simple_dsp  used to calculate quality cuts with peakfiles \n\n\n\n\n\n","category":"method"},{"location":"api/#Juleanita.sktutek_csv_to_lh5","page":"API","title":"Juleanita.sktutek_csv_to_lh5","text":"skutek_csv_to_lh5(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId, csv_folder::String; timestep::Quantity = 0.01u\"¬µs\")\n skutek_csv_to_lh5(data::LegendData, period::DataPeriod, run::DataRun, category::Union{Symbol, DataCategory}, channel::ChannelId; kwargs...)\n\nconvert csv files from Skutek digitizer \"FemtoDAQ Vireo\" to lh5 files\n\nformat of csv file matches the one of  Skutek digitizer \"FemtoDAQ Vireo ...might be different for other systems\n\ninputs:\n\ndata::LegendData LegendData object. You need \"LEGEND_DATA_CONFIG\" to construct this. this will define later where .lh5 files are saved\nperiod::DataPeriod data period that you want to assign your data to\nrun::DataRun data run that you want to assign your data to\ncategory::DataCategoryLike data category that you want to assign your data to\nchannel::ChannelId channel id that you want to assign your data to\ncsv_folder::String folder where the csv files are located (optinal). if not defined use the default folder\n\nkwargs\n\ntimestep::Quantity time step of the waveforms.  default is 0.01¬µs ‚Äì> 100 MHz sampling. \nchmode::Symbol = :diff \n:diff  ch1 - ch2 is stored as raw/waveform\n:diffplus ch1 - ch2 is stored as raw/waveform AND both channels are stored as raw/waveform_ch1 and raw/waveform_ch2 (if available in data)\n:single ch1 is stored as raw/waveform and ch2 is stored as raw/waveform_ch2 (if available in data)\n:pulser ch1 is stored as raw/waveform and ch2 is stored as raw/pulser\n\n\n\n\n\n","category":"function"},{"location":"LICENSE/#LICENSE","page":"LICENSE","title":"LICENSE","text":"","category":"section"},{"location":"LICENSE/","page":"LICENSE","title":"LICENSE","text":"using Markdown\nMarkdown.parse_file(joinpath(@__DIR__, \"..\", \"..\", \"LICENSE.md\"))","category":"page"},{"location":"tutorials/getting_started/#**Remarks**","page":"Getting Started","title":"üí° Remarks","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"This document provides a step-by-step guide for the initial setup of Juleanita on NERSC, using data from the LBNL teststand as an example.   If you plan to use a different set of teststand data, the overall logic remains the same, but you will need to adjust the file paths accordingly.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Working on NERSC is the most straighforward way to analyse LBNL teststand data, because:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Teststand data is stored on NERSC \nMetadata repository is already cloned into the correct location \nConfiguration file for LegendDataManagement is already in place","category":"page"},{"location":"tutorials/getting_started/#1.-NERSC-account","page":"Getting Started","title":"1. NERSC account","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Get a NERSC account. For instructions see Legend confluence","category":"page"},{"location":"tutorials/getting_started/#2.-SSH-connection","page":"Getting Started","title":"2. SSH connection","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Once you have a NERSC account, you can log in via ssh: ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Create MFA (multi-factor authetification) to get OPT (one-time-password):\nOnce you have the account and MFA set up, you can login to NERSC:\n``` bash","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"   ssh <username>@perlmutter.nersc.gov\n```\nreplace `<username>` with your NERSC username.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Optional (but highly recommended): Download sshproxy.sh\nThis creates ssh key that is valid 24 hours. No need to retype password+OTP everytime","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"* usage:\n ``` bash\n ./sshproxy.sh -u <username>   \n```","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Save connection in ~/.ssh/config config to make connecting easier. Then login via ssh perlmutter","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Host perlmutter\n    HostName perlmutter.nersc.gov\n    User <username>\n    IdentityFile ~/.ssh/nersc\n    IdentitiesOnly yes\n    ForwardAgent yes","category":"page"},{"location":"tutorials/getting_started/#3.-VSCode","page":"Getting Started","title":"3. VSCode","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Though not mandatory, I highly recommend to download and install the IDE VSCode.  In addition, I'd recomment to install the following VSCode extentions: ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Julia: language support\nRemote - SSH: allows you to connect to a remote, such as NERSC, inside VSCode.\nGitHub Copilot (requires GitHub Pro account): AI chat & coding help inside VSCode","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"To start a session on NERSC, open VSCode on your computer as usual. Then connect to NERSC via Connect to Host (bottom left) and select perlmutter. This will connect you to a NERSC login node. ","category":"page"},{"location":"tutorials/getting_started/#4.-Julia-on-NERSC","page":"Getting Started","title":"4. Julia on NERSC","text":"","category":"section"},{"location":"tutorials/getting_started/#4.1-Installation","page":"Getting Started","title":"4.1 Installation","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"You don't have to install Julia on NERSC yourself, because there are already several versions available, which are updated regularly. See /global/common/software/nersc/n9/julia/ for available versions. At the time of this writing the newest version is 1.10.4. ","category":"page"},{"location":"tutorials/getting_started/#4.2-Julia-Executable","page":"Getting Started","title":"4.2 Julia Executable","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"When you start working with Julia on NERSC, some julia settings that have to be modified. You can access the julia settings in VSCode with  Settings -> Remote [SSH: permutter]-> Extensions -> julia.","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Julia Executable Path: this tells VSCode which julia installation you want to use (modify path if you want a different version). ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"-> Julia: Executable Path =  /global/common/software/nersc/n9/julia/1.10.4/bin/julia","category":"page"},{"location":"tutorials/getting_started/#4.3-Start-Julia-session","page":"Getting Started","title":"4.3 Start Julia session","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"To start a julia session, you can just type julia into the VSCode terminal window. Another way to start julia is via the Command Palette (Command + Shift + P) -> Julia: Start REPL. ","category":"page"},{"location":"tutorials/getting_started/#5.-Julia-package-manager-and-Legend-registry","page":"Getting Started","title":"5. Julia package manager and Legend registry","text":"","category":"section"},{"location":"tutorials/getting_started/#5.1-Package-manager","page":"Getting Started","title":"5.1 Package manager","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"Julia has a built-in package manager. To enter the package manager inside  julia session type ]","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> ]","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"To get a list of packages in your julia environment type (from package manager):","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"pkg> st","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"To add a package to  your julia environment type (from package manager):","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"pkg> add <package-name>","category":"page"},{"location":"tutorials/getting_started/#5.2-Legend-registry","page":"Getting Started","title":"5.2 Legend registry","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"To be able to add and use Legend-specific Julia packages, you need to add the Legend registry:  ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"julia> include(download(\"https://raw.githubusercontent.com/legend-exp/legend-julia-tutorial/main/legend_julia_setup.jl\"))","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"This needs to be done only once. For reference see Julia Software Stack (Confluence).","category":"page"},{"location":"tutorials/getting_started/#6.-LBNL-Teststand-data","page":"Getting Started","title":"6. LBNL Teststand data","text":"","category":"section"},{"location":"tutorials/getting_started/#6.1-Where-is-the-data-on-NERSC?","page":"Getting Started","title":"6.1 Where is the data on NERSC?","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"The LBNL teststand data is located on NERSC under this path: ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"/global/cfs/projectdirs/m2676/data/teststands/lbnl/ppc01/","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"This folder contains","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"config.json\nthis is a configuration file that defines where the raw data, intermediate and final results are saved\nteststand-metadata\nContains documentation and metadata for germanium detector and electronics\nContains configuration for processing (such as baseline window or gamma peak energies)\nfor more information see git repo README\ngenerated \nthis is where all the data lies\njlpar: results from processors, for example: decay time or energy calibration function\njlplt: processing plots\njlreport: space for processing reports. Not used at the moment. \ntier/: \njldsp/: dsp results\njlhit/: hit files (calibrated spectra)\njlpeaks/ peak files\nraw_csv/ waveforms in csv format (from DAQ)\nraw/ waveforms better compressed in lh5 format (this is what LegendDataManagement needs)","category":"page"},{"location":"tutorials/getting_started/#6.2-How-can-I-access-the-data?","page":"Getting Started","title":"6.2 How can I access the data?","text":"","category":"section"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"To load and save data using the data management package LegendDataManagement.jl (a dependency of Juleanita), you need to define the environmental variable \"LEGEND_DATA_CONFIG\". This variable should point to a config.json file in your data production. The config for the main LBNL production on NERSC is located here","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"/global/cfs/projectdirs/m2676/data/teststands/lbnl/ppc01/config.json","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"This file tells LegendDataManagement where it can find the raw waveforms, dsp results, energy calibration function etc. ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"You should define \"LEGEND_DATA_CONFIG\" in two places: ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"your .bashrc as:","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"export LEGEND_DATA_CONFIG=\"/global/cfs/projectdirs/m2676/data/teststands/lbnl/ppc01/config.json\"","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"In your VSCode julia extension, you should also add the same config path to your VSCode [remote] settings. ","category":"page"},{"location":"tutorials/getting_started/","page":"Getting Started","title":"Getting Started","text":"\"terminal.integrated.env.linux\": {\n            \"LEGEND_DATA_CONFIG\": \"/global/cfs/projectdirs/m2676/data/teststands/lbnl/ppc01/config.json\"\n        },","category":"page"},{"location":"tutorials/getting_started/#Now-you-are-ready-to-start-using-Juleanita-with-your-teststand-data.","page":"Getting Started","title":"Now you are ready to start using Juleanita with your teststand data.","text":"","category":"section"},{"location":"tutorials/reading_data/#read_data","page":"Basic I/O","title":"read_data","text":"","category":"section"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"A basic introduction on how to read data using LegendDataManagement","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"First you have to load the required packages","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"using LegendDataManagement\nusing LegendHDF5IO\nusing TypedTables","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"Now you define which data set you want to read. For more information on the datasets, check out the documentation in teststand-metadata","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"category = DataCategory(:cal)\nperiod = DataPeriod(3)\nrun = DataRun(1)\nchannel = ChannelId(1) # channel 1 => PPC01 in LBNL-70-141","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"Create LegendData object","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"asic = LegendData(:ppc01)","category":"page"},{"location":"tutorials/reading_data/#Read-the-\"raw\"-tier-(waveforms)","page":"Basic I/O","title":"Read the \"raw\" tier (waveforms)","text":"","category":"section"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"filekeys = search_disk(FileKey, asic.tier[DataTier(:raw), category , period, run])\ndata_raw = Table(read_ldata(asic, DataTier(:raw), filekeys, channel))\nwaveforms = data_raw.waveform","category":"page"},{"location":"tutorials/reading_data/#Read-the-\"dsp\"-tier","page":"Basic I/O","title":"Read the \"dsp\" tier","text":"","category":"section"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"data_dsp = Table(read_ldata(asic, DataTier(:jldsp), filekeys, channel))","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"this data contains many variables, like the different energy estimates such as","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"data_dsp.e_trap","category":"page"},{"location":"tutorials/reading_data/#Read-the-\"hit\"-tier","page":"Basic I/O","title":"Read the \"hit\" tier","text":"","category":"section"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"data_hit = Table(read_ldata(asic, DataTier(:jlhit), filekeys, channel))","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"this data contains the hit information, such as the calibrated energyes and quality cuts flags","category":"page"},{"location":"tutorials/reading_data/#Read-the-\"pars\"","page":"Basic I/O","title":"Read the \"pars\"","text":"","category":"section"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"Saved parameters, can be access with the following synthax:","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"pars = asic.par[category].rpars","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"here are some example to lad specific parameters:","category":"page"},{"location":"tutorials/reading_data/","page":"Basic I/O","title":"Basic I/O","text":"pars_pole_zero = pars.pz[period, run, channel]\npars_energy = pars.ecal[period, run, channel].e_trap\ngamma_peaks = [pars_energy.fit[peak].fwhm for peak in [:Co60a, :Co60b]]\nqc_flag =  pars.qc[period, run, channel].wvf_keep.all","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Juleanita","category":"page"},{"location":"#Juleanita","page":"Home","title":"Juleanita","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Juleanita. Juleanita is a meta-package for the Julia software stack to analyse teststand data for the LEGEND experiment.","category":"page"},{"location":"#Install","page":"Home","title":"Install","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"pkg> add https://github.com/legend-exp/Juleanita.jl.git","category":"page"}]
}
